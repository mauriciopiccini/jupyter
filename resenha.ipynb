{
  "cells": [
    {
      "id": "fad5bf2a-cd72-4774-9c11-980627418b6c",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "a0f47b36-a83d-46ff-b9bc-875c36c70db9"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T17:54:35.257744+00:00",
          "start_time": "2023-08-18T17:54:35.101903+00:00"
        }
      },
      "execution_count": null,
      "source": "# input cell\n# é possível adicionar um input aqui?",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b67fc23",
      "metadata": {
        "noteable": {
          "output_collection_id": "af13095e-e768-4a53-a378-01a7e36c5eb6"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T18:00:47.156429+00:00",
          "start_time": "2023-08-18T17:59:50.825408+00:00"
        }
      },
      "outputs": [],
      "source": "!pip install nltk\n!pip install networkx\n!pip install textblob\n!pip install mercury"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "788ba3c7",
      "metadata": {
        "scrolled": true,
        "noteable": {
          "output_collection_id": "9ec55c0e-dae8-4b4e-b5ce-33462075b8de"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T18:30:34.126693+00:00",
          "start_time": "2023-08-18T18:30:33.957619+00:00"
        }
      },
      "outputs": [],
      "source": "# Importa bibliotecas necessárias\nimport requests\nfrom bs4 import BeautifulSoup\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.cluster.util import cosine_distance\nimport numpy as np\nimport networkx as nx\nimport mercury as mr\nimport re\n\nfrom textblob import TextBlob\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nnltk.download('punkt')\nnltk.download('vader_lexicon')\nnltk.download('stopwords')\nsia = SentimentIntensityAnalyzer()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1078ec2",
      "metadata": {
        "noteable": {
          "output_collection_id": "e42c7b56-1089-496e-927a-a45ee275d31f"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T18:50:17.221392+00:00",
          "start_time": "2023-08-18T18:50:17.053979+00:00"
        }
      },
      "outputs": [],
      "source": "# gerar gráfico de sentimento\ndef create_array_sentiment(url, resumo=False, imprime=False):\n    # Faz request do artigo e extrai o texto\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    paragraphs = soup.find_all('div', attrs={\"class\": \"curva2-5\"})\n\n    article_text = [paragraph.text for paragraph in paragraphs]\n    article_text = ' '.join(article_text)\n\n    # Resumo do texto usando algoritmo TextRank\n    sentences = nltk.sent_tokenize(article_text)\n    stopwords = nltk.corpus.stopwords.words('portuguese')\n    word_frequencies = {}  \n    for word in nltk.word_tokenize(article_text):  \n        if word not in stopwords:\n            if word not in word_frequencies.keys():\n                word_frequencies[word] = 1\n            else:\n                word_frequencies[word] += 1\n\n    maximum_frequncy = max(word_frequencies.values())\n\n    for word in word_frequencies.keys():  \n        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n\n    sentence_scores = {}  \n    for sent in sentences:  \n        for word in nltk.word_tokenize(sent.lower()):\n            if word in word_frequencies.keys():\n                if len(sent.split(' ')) < 30:\n                    if sent not in sentence_scores.keys():\n                        sentence_scores[sent] = word_frequencies[word]\n                    else:\n                        sentence_scores[sent] += word_frequencies[word]\n\n    import heapq  \n    summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n    summary = ' '.join(summary_sentences)\n    if resumo:\n        mr.Md(\"## Resumo:\")\n        mr.Md(summary)\n\n    if imprime:\n        mr.Md(f\"## Sentimento: {url}\")\n\n    # Análise de sentimento frase a frase\n    sentiment_values = []\n    TAG_RE = re.compile('<br>')\n    for sentence in sentences:\n        sentence = TAG_RE.sub('', sentence)\n        sentence = sentence.replace(\"<p>\", \"\")\n        sentence = sentence.replace(\"<p/>\", \"\")\n        sentence = sentence.replace(\"<br>\", \"\")\n        sentence = sentence.replace(\"<BR>\", \"\")\n        blob = TextBlob(sentence)\n        sentiment = blob.sentiment.polarity\n        #sentiment = sia.polarity_scores(sentence)['compound']\n        if sentiment > 0:\n            if imprime:\n                mr.Md(f\"<div style='background-color:#ccf'>{sentence} - <b>positivo</b> {sentiment}</div>\")\n        elif sentiment < -0:\n            if imprime:\n                mr.Md(f\"<div style='background-color:#fcc'>{sentence} - <b>negativo</b> {sentiment}</div>\")\n        #else:\n            #if imprime:\n                # se neutro, não imprime nada, por isso, comentado\n                #print(sentence, f'- neutro {sentiment}')\n                #sentence = sentence\n        sentiment_values.append(sentiment)\n    return sentiment_values"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8db96bb",
      "metadata": {
        "scrolled": false,
        "noteable": {
          "output_collection_id": "72723c92-5ac5-4a58-afbb-3085aacd6bfc"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T18:45:45.148125+00:00",
          "start_time": "2023-08-18T18:45:44.989432+00:00"
        }
      },
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef chart_sentiment(url, resumo=False, imprime=False):\n    # print URL analyzed\n    # print(url)\n    sentiment_values = create_array_sentiment(url, imprime=imprime, resumo=resumo)\n    # Increase the size of the plot\n    plt.figure(figsize=(20, 1))  # Adjust the width and height as desired\n    # Adjust the font size of column labels\n    plt.xticks(fontsize=14)\n    # Create a heatmap using seaborn\n    sns.heatmap([sentiment_values], cmap='coolwarm_r', annot=True, vmin=-1, vmax=1)\n    # Display the heatmap\n    plt.show()\n"
    },
    {
      "id": "86cd009c-a47f-40ff-a899-29adac8ef08f",
      "cell_type": "markdown",
      "source": "# Snowglobe @ Skoob",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f208efc6",
      "metadata": {
        "scrolled": true,
        "noteable": {
          "output_collection_id": "8152db91-2fe4-4549-8d92-a0928d1a5eb2"
        },
        "ExecuteTime": {
          "end_time": "2023-08-18T18:50:24.336408+00:00",
          "start_time": "2023-08-18T18:50:22.296689+00:00"
        }
      },
      "outputs": [],
      "source": "# snowglobe\nchart_sentiment(\"https://www.skoob.com.br/livro/resenhas/985641/edicao:987022\", resumo=True, imprime=True)\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "noteable": {
      "last_transaction_id": "7c42102e-c5a6-471d-bca0-458f1d2fa3fa"
    },
    "selected_hardware_size": "small",
    "kernel_info": {
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
